{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"/home/nakamura/inflated_convnets_pytorch/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from IPython import embed\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.i3dense import I3DenseNet\n",
    "from src.i3res import I3ResNet\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "dataset = datasets.ImageFolder('data/dummy-dataset',\n",
    "                               transforms.Compose([\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   normalize,\n",
    "                               ]))\n",
    "\n",
    "class_idx = json.load(open('data/imagenet_class_index.json'))\n",
    "imagenet_classes = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamura/.conda/envs/video/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet50(pretrained=True)\n",
    "densenet = torchvision.models.densenet169(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1664, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3resnet = I3ResNet(copy.deepcopy(resnet), 16)\n",
    "i3densenet = I3DenseNet(copy.deepcopy(densenet), 16, inflate_block_convs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 1, 7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i3densenet.features.conv0.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_2d, target) in enumerate(loader):\n",
    "    \n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        input_2d_var = torch.autograd.Variable(input_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I3ResNet(\n",
       "  (conv1): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), dilation=(1, 1, 1), ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck3d(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck3d(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck3d(\n",
       "      (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck3d(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck3d(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck3d(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck3d(\n",
       "      (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck3d(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck3d(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck3d(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck3d(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck3d(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck3d(\n",
       "      (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck3d(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck3d(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck3d(\n",
       "      (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool3d(kernel_size=(1, 7, 7), stride=(1, 1, 1), padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()\n",
    "i3resnet.eval()\n",
    "#densenet.eval()\n",
    "# i3densenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv3d"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2d = resnet(input_2d_var)\n",
    "# o2d = densenet(input_2d_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3d = input_2d.unsqueeze(2).repeat(1, 1, 16, 1, 1)\n",
    "input_3d_var = torch.autograd.Variable(input_3d)\n",
    "\n",
    "out3d = i3resnet(input_3d_var)\n",
    "# out3d = i3densenet(input_3d_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = i3densenet.features.conv0.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0417,  0.0374, -0.0592,  0.0340, -0.0718,  0.0629, -0.0469],\n",
       "        [ 0.0733, -0.0756,  0.0889, -0.0476,  0.1333, -0.1627,  0.1147],\n",
       "        [-0.0467,  0.0538,  0.0289, -0.1911,  0.0510,  0.0981, -0.1086],\n",
       "        [ 0.0494, -0.0352, -0.1733,  0.5272, -0.4474,  0.1504,  0.0110],\n",
       "        [-0.0825,  0.1483,  0.0194, -0.4137,  0.4615, -0.2388,  0.0455],\n",
       "        [ 0.0598, -0.1716,  0.1396,  0.1027, -0.2098,  0.1354, -0.0345],\n",
       "        [-0.0284,  0.0956, -0.1265,  0.0404,  0.0283, -0.0240,  0.0101]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re[0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0124, -0.0042,  0.0634,  0.0147, -0.0582, -0.0483, -0.0051],\n",
       "          [-0.0055, -0.0465,  0.1243,  0.1283, -0.0801, -0.0434,  0.0037],\n",
       "          [-0.0014, -0.1201,  0.0349,  0.2919, -0.0808, -0.1060, -0.0022],\n",
       "          [ 0.0125, -0.1254, -0.1034,  0.3776,  0.0926, -0.1554, -0.0236],\n",
       "          [ 0.0191, -0.0585, -0.1907,  0.1829,  0.2773, -0.1029, -0.0619],\n",
       "          [ 0.0091, -0.0144, -0.1578, -0.0070,  0.2052,  0.0434, -0.0548],\n",
       "          [-0.0044,  0.0078, -0.1058, -0.0658,  0.0812,  0.0591,  0.0057]]],\n",
       "\n",
       "\n",
       "        [[[-0.0238, -0.0351,  0.0744,  0.0406, -0.0601, -0.0623, -0.0109],\n",
       "          [-0.0203, -0.0964,  0.1427,  0.1788, -0.0907, -0.0620, -0.0031],\n",
       "          [-0.0192, -0.1834,  0.0365,  0.3881, -0.0735, -0.1461, -0.0198],\n",
       "          [ 0.0032, -0.1855, -0.1681,  0.4692,  0.1664, -0.1746, -0.0494],\n",
       "          [ 0.0107, -0.1147, -0.2910,  0.2082,  0.3723, -0.0768, -0.0721],\n",
       "          [ 0.0393, -0.0254, -0.2122, -0.0348,  0.2498,  0.0775, -0.0613],\n",
       "          [ 0.0086,  0.0125, -0.1391, -0.0958,  0.0826,  0.0526, -0.0065]]],\n",
       "\n",
       "\n",
       "        [[[-0.0082, -0.0158,  0.0296,  0.0135, -0.0086, -0.0027,  0.0118],\n",
       "          [ 0.0026, -0.0503,  0.0551,  0.0557, -0.0352,  0.0071,  0.0123],\n",
       "          [ 0.0315, -0.0830, -0.0388,  0.1470, -0.0786, -0.0255,  0.0267],\n",
       "          [ 0.0360, -0.0486, -0.1257,  0.1740, -0.0034, -0.0818,  0.0198],\n",
       "          [ 0.0313, -0.0036, -0.1421,  0.0522,  0.1397, -0.0682, -0.0109],\n",
       "          [ 0.0367,  0.0466, -0.0824, -0.0492,  0.0932,  0.0199, -0.0241],\n",
       "          [ 0.0026,  0.0460, -0.0394, -0.0504,  0.0188,  0.0140, -0.0149]]]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1352,  0.5686, -0.3020, -0.8421, -2.4755,  0.4750, -2.5059,  0.4557,\n",
       "          1.6123, -2.4777, -2.1154, -2.9493, -3.9388, -2.3731, -3.0658, -2.8181,\n",
       "         -2.6578,  1.1197, -1.4043, -4.7591, -0.9188, -2.7249, -2.0153,  0.6596,\n",
       "         -3.9580, -0.9696, -4.0192, -2.4665, -1.2398, -2.9984, -0.9034, -2.6463,\n",
       "         -2.8501,  0.7978,  1.6862, -0.0435, -0.2760, -0.5255, -1.8023, -0.2209,\n",
       "         -1.3988, -2.3441, -0.7008, -1.1933, -1.6738,  0.5851, -0.9874, -1.5761,\n",
       "         -1.4122, -0.0936, -1.0265,  1.1201, -1.2572, -0.5665,  0.6027,  0.6223,\n",
       "         -1.7992, -2.2367, -1.6462,  0.1308,  1.0655,  0.4588,  0.8249, -0.0340,\n",
       "          0.7624, -0.5482,  0.2067,  1.4092, -0.9917, -1.8442, -3.1534,  0.5715,\n",
       "         -5.3509, -4.2268, -2.3494, -4.9101, -1.3518, -1.3526, -2.1727, -1.1525,\n",
       "         -0.7463, -3.5708, -0.7887, -1.8128, -1.6380, -3.8108, -1.0554, -3.6473,\n",
       "          0.7743, -1.0726, -0.9451, -2.7253,  0.5058, -0.8943, -0.8228, -4.9976,\n",
       "         -2.8386, -0.0213, -1.5376, -0.7950, -0.7485, -2.1805, -2.0823, -0.7863,\n",
       "          4.7788, -0.8694,  2.7216, -0.8821, -0.7943,  0.2446, -3.3281, -1.8749,\n",
       "          1.5438, -0.4282, -0.1264, -0.3243, -2.1284, -0.7973, -1.3957, -1.4824,\n",
       "         -3.4727, -1.0748, -1.3531, -2.0154, -1.0482, -0.0443, -1.8824, -1.3472,\n",
       "         -1.8415, -2.8166, -1.3718, -2.9462, -2.3124, -1.3386, -2.3610, -3.4068,\n",
       "          1.7981, -1.3449, -3.3520, -0.9344, -2.3030, -2.1709, -2.1554, -1.5326,\n",
       "         -1.2705,  0.3458, -1.8377, -1.4866, -0.0675, -1.7820,  0.6198,  6.8438,\n",
       "         -3.3673, -2.5021,  0.0011, -1.9183, -1.8066,  0.0293,  1.8152,  5.1986,\n",
       "         -2.3705,  4.0607,  4.1216,  3.4456,  0.6853, -0.0350,  0.0150,  1.7731,\n",
       "          5.1171, -1.0200,  0.1094,  0.6832,  3.2536,  5.9839,  4.4928, -2.0295,\n",
       "          1.0900, -1.7018, -0.1681,  3.1921,  2.7902, -3.1004,  2.6421, -3.1488,\n",
       "          2.9470,  4.3744,  7.1973, -0.5212, -0.1732,  0.9542, -3.2257, -0.8231,\n",
       "          2.6359,  3.6359,  1.5711,  2.4279, -0.2935, -1.7243, -0.9673,  2.7142,\n",
       "          1.7993,  0.4845,  1.0213,  2.5448,  0.7327,  1.1386, -0.0165,  5.3669,\n",
       "          5.6614,  3.4068, -2.7732,  0.3026, -3.3182,  0.8574, -0.8420,  0.7668,\n",
       "         -0.3659, -2.8948,  2.0023,  1.1633,  0.4557, -2.5492,  3.3509,  3.3849,\n",
       "          2.6735,  5.9382,  0.1468,  9.7196, -1.4220, -1.1394,  1.1534,  4.0719,\n",
       "          4.4139, -1.1078,  3.9093,  8.2481,  1.5469,  1.2354,  4.5599,  1.8803,\n",
       "          5.4945,  5.0317, -0.1923,  2.6087,  4.5648,  3.8550,  2.6322,  3.5233,\n",
       "          5.6851,  4.2846,  4.5231,  0.6314, -3.2335,  6.2880,  1.8805,  1.7505,\n",
       "          1.3225,  1.2951,  0.7262,  0.2651,  5.5641, -2.4990,  1.3760, 12.4876,\n",
       "         14.1910, -1.9291, -2.0476, -0.6310, -0.2215,  3.3637,  2.3708,  5.2667,\n",
       "          2.9330, 12.3440,  7.8750,  4.4993,  2.3750,  3.3279,  2.2647,  0.5771,\n",
       "          1.9004,  2.3753,  3.5240, -2.0184,  2.3710,  3.0272,  5.4633, -0.2679,\n",
       "          0.1755, -2.1435,  2.1586,  2.5955,  2.6817,  0.9060,  3.2671,  1.9147,\n",
       "          2.5075, -1.6110,  0.3302,  0.2779, -1.9749, -1.1098, -3.1183, -4.0548,\n",
       "         -1.8561,  1.3925, -2.1019, -2.7436, -2.5336, -0.7168,  0.4371, -2.1029,\n",
       "         -0.6497, -1.7488, -0.5874, -2.9675, -4.1084, -3.8816, -4.7398, -0.4224,\n",
       "         -3.7852, -2.6514, -4.0440, -3.0990, -4.8376, -1.6846, -0.5186, -0.4872,\n",
       "         -2.1851, -1.8954,  1.9522,  1.1831, -0.7713,  0.0233, -4.3320, -1.9436,\n",
       "         -1.0477,  1.4505, -0.5847,  2.4431, -0.4951,  1.8759,  0.7872,  0.0576,\n",
       "         -0.3824, -0.1273, -0.9738, -0.5665,  1.1370,  0.6200,  1.6248, -2.3662,\n",
       "          2.0814,  1.7288,  0.8679,  1.7426,  1.1354, -0.2981, -2.6617, -1.5547,\n",
       "          1.3850, -2.0409, -1.4028, -0.7321, -3.4640, -2.9819, -2.6630, -4.1076,\n",
       "         -2.7932, -3.0444, -2.3637, -1.5799, -1.9078,  0.9691, -3.5489, -4.9273,\n",
       "         -0.9133, -3.8445, -1.3121, -2.2850, -3.7004, -4.0196, -2.6402, -2.1428,\n",
       "         -0.8070, -3.3246, -1.2014, -0.6286, -1.0710, -2.1140, -2.1718, -2.0385,\n",
       "         -0.5831, -3.2216, -1.0939, -2.9304, -2.0039, -3.0524,  1.0534, -0.7816,\n",
       "         -0.7115,  0.6067,  0.6326, -1.1331, -1.6624, -1.1570, -2.1382,  0.4169,\n",
       "          0.1104,  1.1511, -1.6179, -0.2261,  3.9423, -2.9732,  2.1299,  0.2878,\n",
       "         -1.4664,  4.2941, -0.5647,  1.4743, -0.9770,  3.9846,  0.2996, -1.0447,\n",
       "         -1.2846,  0.8599, -0.0472,  3.8075,  4.6810,  0.8137,  1.2484, -1.8368,\n",
       "         -3.0720,  3.2433, -0.2696,  2.6845,  1.7082,  1.6150, -0.0757, -2.3237,\n",
       "         -1.1911, -0.6173, -1.2857, -1.1226, -1.4065, -0.1713, -0.3852,  1.3747,\n",
       "         -2.2299,  2.0623, -1.1845, -0.8498,  0.9502,  1.9752,  1.0723, -0.9328,\n",
       "         -0.1155,  1.5396,  1.1192, -0.9928,  2.3711, -3.7020,  0.9931,  4.1533,\n",
       "         -1.7283,  1.6891, -3.0095, -2.6689,  0.7851, -1.0065,  0.9663, -0.9065,\n",
       "          4.3116, -2.5134, -1.5418,  1.9170, -2.9068, -1.9383,  2.6041,  4.0998,\n",
       "          1.9455, -1.3124,  0.6401, -0.6201, -0.4696,  0.1072, -2.3269,  1.4957,\n",
       "          2.0432,  1.8516, -3.3997,  0.8594, -1.2192, -1.8878, -2.9890, -1.4631,\n",
       "         -2.7949,  1.8251, -1.8395, -2.6047,  0.5740, -0.8388,  1.0972, -1.4773,\n",
       "          2.2617,  0.6735,  4.2724, -1.7474,  2.9145, -0.7844,  1.8564, -1.4891,\n",
       "         -1.4318,  0.3220,  1.1890,  3.8085, -0.5082,  2.3856,  1.0987,  1.9426,\n",
       "         -1.4391, -2.6280,  1.0689,  1.0355, -2.3867,  0.6577, -0.3491,  0.4771,\n",
       "         -0.5025, -0.6359, -0.0216,  1.2919, -1.5035, -1.9308,  0.3610, -1.8770,\n",
       "          0.8332,  2.0893,  1.3117,  4.7560, -0.6500,  2.1035,  1.9033,  4.2718,\n",
       "         -0.1827,  1.2656, -1.3715, -2.1016,  0.7294, -0.2743, -3.1724,  0.4669,\n",
       "          0.5709, -0.3396, -2.8808, -1.0406,  0.1006,  0.2966, -1.1498,  1.3360,\n",
       "         -2.6534, -0.5547,  0.5969, -2.5038, -3.1051,  1.7241, -0.4476, -1.0318,\n",
       "         -0.9019,  1.5767, -2.7049, -1.3265,  1.3847, -4.2169,  2.6658, -1.0223,\n",
       "         -0.9035, -0.7216,  2.8301,  1.7341,  2.4855, -0.0819, -1.0636, -2.7320,\n",
       "         -2.1110, -1.8547, -1.6965, -0.2925,  0.7507, -1.9692,  1.5363,  0.9578,\n",
       "         -1.3789, -0.9969, -1.6120,  1.9277, -0.0153, -2.7774,  1.3425,  0.7130,\n",
       "          0.1299, -1.3380,  1.0192, -1.3363,  1.8025,  0.8566, -1.0189,  0.0503,\n",
       "         -0.4590,  2.1751, -0.0471, -0.3411, -2.2482, -1.3001,  0.1361, -0.0610,\n",
       "          0.8433, -1.3322,  0.2334, -0.8519,  2.5251,  1.3814,  2.8854, -2.9743,\n",
       "          0.6801, -0.3890, -0.9450, -1.5942, -1.4330,  1.2141,  1.7042,  0.6328,\n",
       "          1.7300, -0.2975,  1.9899,  0.8237, -0.7278,  1.3999,  0.1064,  0.5091,\n",
       "         -0.6575, -0.0311,  0.2598, -2.2883,  0.1810, -1.6521,  2.4930, -0.2217,\n",
       "         -3.9868, -0.1494, -1.5395, -1.5233,  0.3296, -0.4387,  0.0445, -1.6165,\n",
       "          1.3870,  1.9169, -0.0932,  1.4000,  0.9643, -2.8173, -1.2771, -1.6554,\n",
       "          3.3963,  0.1101,  2.2990, -0.4802, -1.1885, -1.5330,  0.4024,  0.4283,\n",
       "          3.0430,  0.9726,  0.9386, -0.0650,  3.2652, -0.3350, -0.8900,  0.6316,\n",
       "          0.4851,  2.3818,  1.1780, -1.4161, -1.5586, -2.4784, -1.2060, -1.7429,\n",
       "          1.5118, -2.4336, -1.2121, -0.9437, -0.1856,  4.1706, -1.9508, -1.3745,\n",
       "          0.4765, -0.4717,  0.7310,  0.2109,  0.8444,  0.2783,  0.2272,  0.7366,\n",
       "          0.2202, -0.1424,  1.1548,  0.8949, -0.8164, -0.0778,  1.7684,  2.6377,\n",
       "         -1.4261,  1.6985,  2.0589, -3.5958,  1.6181,  0.5469,  0.8162,  0.7251,\n",
       "          0.8986, -2.4411,  3.9224,  3.4933, -1.9051,  1.3153, -1.5526, -0.1175,\n",
       "          1.2775, -3.2572,  4.4933,  2.0216,  1.8482,  0.6831, -2.2933, -2.3998,\n",
       "         -1.4533, -0.2911,  1.3054, -1.4579, -0.9584,  1.7704,  3.1857, -0.0168,\n",
       "          1.6033, -2.0639, -0.4896, -1.0715, -1.1764, -0.4985,  3.2467,  0.2759,\n",
       "          2.0292, -0.3297,  2.0740,  3.5997,  2.1953,  1.1271, -0.7873,  0.7321,\n",
       "         -1.0299,  3.9477, -0.8738, -1.8405, -0.3739,  0.7954, -1.6249,  0.7446,\n",
       "          0.4387, -0.1411,  1.6932,  0.7145, -2.0173, -1.6689,  1.1983,  0.9701,\n",
       "          0.2672, -3.1192,  1.4884,  0.4641, -1.7423, -1.2229,  4.7238, -0.1705,\n",
       "          0.5451, -0.8452, -1.2473, -0.7336, -0.8935,  3.7060,  0.5251,  0.1453,\n",
       "          4.1283,  0.1705,  0.1065,  2.0073, -1.6950,  3.1784, -2.3632,  4.3064,\n",
       "         -1.4561,  1.1369,  1.5299, -1.1965,  0.4397,  5.9483,  0.8416,  3.2205,\n",
       "          1.6005,  0.1215,  0.7246,  1.6209, -0.6876, -0.6697,  0.1608, -0.8151,\n",
       "         -1.6048,  0.7055,  2.5804,  1.8691, -3.1533,  0.9349, -0.3521, -0.0217,\n",
       "          0.8969,  1.7209,  1.5179, -1.1300, -1.1014, -1.3782,  0.3811,  0.7136,\n",
       "         -0.4253, -2.2727,  0.8075, -0.6516,  2.3845,  3.1510, -0.1903, -1.1650,\n",
       "          0.3092,  0.7297, -0.3884,  1.9889, -0.7044, -0.8256, -1.2542, -0.8072,\n",
       "          1.5273, -0.4264,  1.3361,  4.6490,  6.8454, -0.6929,  0.7599, -1.2460,\n",
       "         -0.0720, -3.4297,  3.6807, -0.9644, -0.4043,  1.8166,  0.8958, -1.3167,\n",
       "         -2.2532, -0.1092,  0.5887,  1.2657,  1.4460, -1.6898,  0.0068,  0.5648,\n",
       "          1.2698, -1.0701, -1.9434,  0.9496,  3.3239, -1.6603, -0.3232,  1.5730,\n",
       "          0.3762, -1.1648,  1.1082,  0.1875, -1.2315,  0.6683, -1.0024, -2.1356,\n",
       "          0.6617, -1.3262,  0.3360, -3.3919,  0.1071, -1.0578, -1.6880, -0.7229,\n",
       "         -0.8533,  0.8213,  3.1199,  2.9273,  0.8096, -2.7121,  0.0646, -1.3115,\n",
       "          2.0799,  1.2497, -1.4001, -1.2775,  1.9296, -1.3456,  1.4513, -0.6743,\n",
       "          0.4134,  2.2225, -1.7278,  1.4551,  5.6764, -0.0156,  0.3924,  0.0911,\n",
       "          1.5074, -0.0708, -1.0860, -1.1633,  0.4460, -2.9950, -3.1890, -0.6879,\n",
       "          1.1363,  3.0768, -0.3199, -0.7194, -2.5093, -2.4685,  0.1866, -1.4805,\n",
       "         -0.5201, -0.8099, -0.8224, -1.1065, -2.9313, -1.7303, -1.5415, -0.1286,\n",
       "         -2.0236,  0.7597, -2.1266,  1.0676, -0.7524,  0.0147,  0.4018,  0.6719,\n",
       "         -2.9889,  0.0349, -0.5125, -2.5842, -1.4396,  0.0696,  3.1220, -3.2473,\n",
       "         -0.5900,  0.7667, -0.1190, -1.9254, -1.9178, -1.4155,  0.5542, -0.7370,\n",
       "          2.9042, -1.7957,  0.6115,  2.7282,  1.3623,  0.6691, -0.2338,  3.0963,\n",
       "         -0.0010,  3.7226,  5.8134,  1.9761,  0.2636,  0.3534,  1.3220, -0.0721,\n",
       "          1.3675, -1.2105, -2.4312,  1.3942,  1.5678, -1.5767,  0.3660, -0.7420,\n",
       "         -1.5857, -1.0233, -2.3150,  0.7148, -0.4784, -1.3332, -0.3022,  2.6777]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1352,  0.5686, -0.3020, -0.8421, -2.4755,  0.4750, -2.5059,  0.4557,\n",
       "          1.6123, -2.4777, -2.1154, -2.9493, -3.9388, -2.3731, -3.0658, -2.8181,\n",
       "         -2.6578,  1.1197, -1.4043, -4.7591, -0.9188, -2.7249, -2.0153,  0.6596,\n",
       "         -3.9580, -0.9696, -4.0192, -2.4665, -1.2398, -2.9984, -0.9034, -2.6463,\n",
       "         -2.8501,  0.7978,  1.6862, -0.0435, -0.2760, -0.5255, -1.8023, -0.2209,\n",
       "         -1.3988, -2.3441, -0.7008, -1.1933, -1.6738,  0.5851, -0.9874, -1.5761,\n",
       "         -1.4122, -0.0936, -1.0265,  1.1201, -1.2572, -0.5665,  0.6027,  0.6223,\n",
       "         -1.7992, -2.2367, -1.6462,  0.1308,  1.0655,  0.4587,  0.8249, -0.0340,\n",
       "          0.7624, -0.5482,  0.2067,  1.4092, -0.9917, -1.8442, -3.1534,  0.5715,\n",
       "         -5.3509, -4.2268, -2.3494, -4.9101, -1.3518, -1.3526, -2.1727, -1.1525,\n",
       "         -0.7463, -3.5708, -0.7887, -1.8128, -1.6380, -3.8108, -1.0554, -3.6473,\n",
       "          0.7743, -1.0726, -0.9451, -2.7253,  0.5058, -0.8943, -0.8228, -4.9976,\n",
       "         -2.8386, -0.0213, -1.5376, -0.7950, -0.7485, -2.1805, -2.0823, -0.7863,\n",
       "          4.7788, -0.8694,  2.7216, -0.8821, -0.7943,  0.2446, -3.3281, -1.8749,\n",
       "          1.5438, -0.4282, -0.1264, -0.3243, -2.1284, -0.7973, -1.3957, -1.4824,\n",
       "         -3.4727, -1.0748, -1.3531, -2.0154, -1.0482, -0.0443, -1.8824, -1.3472,\n",
       "         -1.8415, -2.8166, -1.3718, -2.9462, -2.3124, -1.3386, -2.3610, -3.4068,\n",
       "          1.7981, -1.3449, -3.3520, -0.9344, -2.3030, -2.1709, -2.1554, -1.5326,\n",
       "         -1.2705,  0.3458, -1.8377, -1.4866, -0.0675, -1.7820,  0.6198,  6.8438,\n",
       "         -3.3673, -2.5021,  0.0011, -1.9183, -1.8066,  0.0293,  1.8152,  5.1986,\n",
       "         -2.3705,  4.0607,  4.1216,  3.4456,  0.6853, -0.0350,  0.0150,  1.7731,\n",
       "          5.1171, -1.0200,  0.1094,  0.6832,  3.2536,  5.9839,  4.4928, -2.0295,\n",
       "          1.0900, -1.7018, -0.1681,  3.1921,  2.7902, -3.1004,  2.6421, -3.1488,\n",
       "          2.9470,  4.3744,  7.1973, -0.5212, -0.1732,  0.9542, -3.2257, -0.8231,\n",
       "          2.6359,  3.6359,  1.5711,  2.4279, -0.2935, -1.7243, -0.9673,  2.7142,\n",
       "          1.7993,  0.4845,  1.0213,  2.5448,  0.7327,  1.1386, -0.0165,  5.3669,\n",
       "          5.6614,  3.4068, -2.7732,  0.3026, -3.3182,  0.8574, -0.8420,  0.7668,\n",
       "         -0.3659, -2.8948,  2.0023,  1.1633,  0.4557, -2.5492,  3.3509,  3.3849,\n",
       "          2.6735,  5.9382,  0.1468,  9.7196, -1.4220, -1.1394,  1.1534,  4.0719,\n",
       "          4.4139, -1.1078,  3.9093,  8.2481,  1.5469,  1.2354,  4.5599,  1.8803,\n",
       "          5.4945,  5.0318, -0.1923,  2.6087,  4.5648,  3.8550,  2.6322,  3.5233,\n",
       "          5.6851,  4.2846,  4.5231,  0.6314, -3.2335,  6.2880,  1.8805,  1.7505,\n",
       "          1.3225,  1.2951,  0.7262,  0.2651,  5.5641, -2.4990,  1.3760, 12.4876,\n",
       "         14.1910, -1.9291, -2.0476, -0.6310, -0.2215,  3.3637,  2.3708,  5.2667,\n",
       "          2.9330, 12.3440,  7.8750,  4.4993,  2.3750,  3.3279,  2.2647,  0.5771,\n",
       "          1.9004,  2.3753,  3.5240, -2.0184,  2.3710,  3.0272,  5.4633, -0.2679,\n",
       "          0.1755, -2.1435,  2.1586,  2.5955,  2.6817,  0.9060,  3.2671,  1.9147,\n",
       "          2.5075, -1.6110,  0.3302,  0.2779, -1.9749, -1.1098, -3.1183, -4.0548,\n",
       "         -1.8561,  1.3925, -2.1019, -2.7436, -2.5336, -0.7168,  0.4371, -2.1029,\n",
       "         -0.6497, -1.7488, -0.5874, -2.9675, -4.1084, -3.8816, -4.7398, -0.4224,\n",
       "         -3.7852, -2.6514, -4.0440, -3.0990, -4.8376, -1.6846, -0.5186, -0.4872,\n",
       "         -2.1851, -1.8953,  1.9522,  1.1831, -0.7713,  0.0233, -4.3320, -1.9436,\n",
       "         -1.0477,  1.4505, -0.5847,  2.4431, -0.4951,  1.8759,  0.7872,  0.0576,\n",
       "         -0.3824, -0.1273, -0.9738, -0.5665,  1.1370,  0.6200,  1.6248, -2.3662,\n",
       "          2.0814,  1.7288,  0.8679,  1.7426,  1.1354, -0.2981, -2.6617, -1.5547,\n",
       "          1.3850, -2.0409, -1.4028, -0.7321, -3.4640, -2.9819, -2.6630, -4.1076,\n",
       "         -2.7932, -3.0444, -2.3637, -1.5799, -1.9078,  0.9691, -3.5489, -4.9273,\n",
       "         -0.9133, -3.8445, -1.3121, -2.2850, -3.7004, -4.0196, -2.6402, -2.1428,\n",
       "         -0.8070, -3.3246, -1.2014, -0.6286, -1.0710, -2.1140, -2.1718, -2.0385,\n",
       "         -0.5831, -3.2215, -1.0939, -2.9304, -2.0039, -3.0524,  1.0534, -0.7816,\n",
       "         -0.7115,  0.6067,  0.6326, -1.1331, -1.6624, -1.1570, -2.1382,  0.4169,\n",
       "          0.1104,  1.1511, -1.6179, -0.2261,  3.9423, -2.9732,  2.1299,  0.2878,\n",
       "         -1.4664,  4.2941, -0.5647,  1.4743, -0.9770,  3.9846,  0.2996, -1.0447,\n",
       "         -1.2846,  0.8599, -0.0472,  3.8075,  4.6810,  0.8137,  1.2484, -1.8368,\n",
       "         -3.0720,  3.2433, -0.2696,  2.6845,  1.7082,  1.6150, -0.0757, -2.3237,\n",
       "         -1.1911, -0.6173, -1.2857, -1.1226, -1.4065, -0.1713, -0.3852,  1.3747,\n",
       "         -2.2299,  2.0623, -1.1845, -0.8498,  0.9502,  1.9752,  1.0723, -0.9328,\n",
       "         -0.1155,  1.5396,  1.1192, -0.9928,  2.3711, -3.7020,  0.9931,  4.1533,\n",
       "         -1.7283,  1.6891, -3.0095, -2.6689,  0.7851, -1.0065,  0.9663, -0.9065,\n",
       "          4.3116, -2.5134, -1.5418,  1.9170, -2.9068, -1.9383,  2.6041,  4.0998,\n",
       "          1.9455, -1.3124,  0.6401, -0.6201, -0.4696,  0.1072, -2.3269,  1.4957,\n",
       "          2.0432,  1.8516, -3.3997,  0.8594, -1.2192, -1.8878, -2.9890, -1.4631,\n",
       "         -2.7949,  1.8251, -1.8395, -2.6047,  0.5740, -0.8388,  1.0972, -1.4773,\n",
       "          2.2617,  0.6735,  4.2724, -1.7474,  2.9145, -0.7844,  1.8564, -1.4891,\n",
       "         -1.4318,  0.3220,  1.1890,  3.8085, -0.5082,  2.3856,  1.0987,  1.9426,\n",
       "         -1.4391, -2.6280,  1.0689,  1.0355, -2.3867,  0.6577, -0.3491,  0.4771,\n",
       "         -0.5025, -0.6359, -0.0216,  1.2919, -1.5035, -1.9308,  0.3610, -1.8770,\n",
       "          0.8332,  2.0893,  1.3117,  4.7560, -0.6500,  2.1035,  1.9033,  4.2718,\n",
       "         -0.1827,  1.2656, -1.3715, -2.1016,  0.7294, -0.2743, -3.1724,  0.4669,\n",
       "          0.5709, -0.3396, -2.8808, -1.0406,  0.1006,  0.2966, -1.1498,  1.3360,\n",
       "         -2.6534, -0.5547,  0.5969, -2.5038, -3.1051,  1.7241, -0.4476, -1.0318,\n",
       "         -0.9019,  1.5767, -2.7049, -1.3265,  1.3847, -4.2169,  2.6658, -1.0223,\n",
       "         -0.9035, -0.7216,  2.8301,  1.7341,  2.4855, -0.0819, -1.0636, -2.7320,\n",
       "         -2.1110, -1.8547, -1.6965, -0.2925,  0.7507, -1.9692,  1.5363,  0.9578,\n",
       "         -1.3789, -0.9969, -1.6120,  1.9277, -0.0153, -2.7774,  1.3425,  0.7130,\n",
       "          0.1299, -1.3380,  1.0192, -1.3363,  1.8025,  0.8566, -1.0189,  0.0503,\n",
       "         -0.4590,  2.1751, -0.0471, -0.3411, -2.2482, -1.3001,  0.1361, -0.0610,\n",
       "          0.8433, -1.3322,  0.2334, -0.8519,  2.5251,  1.3814,  2.8854, -2.9743,\n",
       "          0.6801, -0.3890, -0.9450, -1.5942, -1.4330,  1.2141,  1.7042,  0.6328,\n",
       "          1.7300, -0.2975,  1.9899,  0.8237, -0.7278,  1.3999,  0.1064,  0.5091,\n",
       "         -0.6575, -0.0311,  0.2598, -2.2883,  0.1810, -1.6521,  2.4930, -0.2217,\n",
       "         -3.9868, -0.1494, -1.5395, -1.5233,  0.3296, -0.4387,  0.0445, -1.6165,\n",
       "          1.3870,  1.9169, -0.0932,  1.4000,  0.9643, -2.8173, -1.2771, -1.6554,\n",
       "          3.3963,  0.1101,  2.2990, -0.4802, -1.1885, -1.5330,  0.4024,  0.4283,\n",
       "          3.0430,  0.9726,  0.9386, -0.0650,  3.2652, -0.3350, -0.8900,  0.6316,\n",
       "          0.4851,  2.3818,  1.1780, -1.4161, -1.5586, -2.4784, -1.2060, -1.7429,\n",
       "          1.5118, -2.4336, -1.2121, -0.9437, -0.1856,  4.1706, -1.9508, -1.3745,\n",
       "          0.4765, -0.4717,  0.7310,  0.2109,  0.8444,  0.2783,  0.2272,  0.7366,\n",
       "          0.2202, -0.1424,  1.1548,  0.8949, -0.8164, -0.0778,  1.7684,  2.6377,\n",
       "         -1.4261,  1.6985,  2.0589, -3.5958,  1.6181,  0.5469,  0.8162,  0.7251,\n",
       "          0.8986, -2.4411,  3.9224,  3.4933, -1.9051,  1.3153, -1.5526, -0.1175,\n",
       "          1.2775, -3.2572,  4.4933,  2.0216,  1.8482,  0.6831, -2.2933, -2.3998,\n",
       "         -1.4533, -0.2911,  1.3054, -1.4579, -0.9584,  1.7704,  3.1857, -0.0168,\n",
       "          1.6033, -2.0639, -0.4896, -1.0715, -1.1764, -0.4985,  3.2467,  0.2759,\n",
       "          2.0292, -0.3297,  2.0740,  3.5997,  2.1953,  1.1271, -0.7873,  0.7321,\n",
       "         -1.0299,  3.9477, -0.8738, -1.8405, -0.3739,  0.7954, -1.6249,  0.7446,\n",
       "          0.4387, -0.1411,  1.6932,  0.7145, -2.0173, -1.6689,  1.1983,  0.9701,\n",
       "          0.2672, -3.1192,  1.4884,  0.4641, -1.7423, -1.2229,  4.7238, -0.1705,\n",
       "          0.5451, -0.8452, -1.2473, -0.7336, -0.8935,  3.7060,  0.5251,  0.1453,\n",
       "          4.1283,  0.1705,  0.1065,  2.0073, -1.6950,  3.1784, -2.3632,  4.3064,\n",
       "         -1.4561,  1.1369,  1.5299, -1.1965,  0.4397,  5.9483,  0.8416,  3.2205,\n",
       "          1.6005,  0.1215,  0.7246,  1.6209, -0.6876, -0.6697,  0.1608, -0.8151,\n",
       "         -1.6048,  0.7055,  2.5805,  1.8691, -3.1533,  0.9349, -0.3521, -0.0217,\n",
       "          0.8969,  1.7209,  1.5179, -1.1300, -1.1014, -1.3782,  0.3812,  0.7136,\n",
       "         -0.4253, -2.2727,  0.8075, -0.6516,  2.3845,  3.1510, -0.1903, -1.1650,\n",
       "          0.3092,  0.7297, -0.3884,  1.9889, -0.7044, -0.8256, -1.2542, -0.8072,\n",
       "          1.5273, -0.4264,  1.3361,  4.6490,  6.8454, -0.6929,  0.7599, -1.2460,\n",
       "         -0.0720, -3.4297,  3.6807, -0.9644, -0.4043,  1.8166,  0.8958, -1.3167,\n",
       "         -2.2532, -0.1092,  0.5887,  1.2657,  1.4460, -1.6898,  0.0068,  0.5648,\n",
       "          1.2698, -1.0701, -1.9434,  0.9496,  3.3239, -1.6603, -0.3232,  1.5730,\n",
       "          0.3762, -1.1648,  1.1082,  0.1875, -1.2315,  0.6683, -1.0024, -2.1356,\n",
       "          0.6617, -1.3261,  0.3360, -3.3919,  0.1071, -1.0578, -1.6880, -0.7229,\n",
       "         -0.8533,  0.8213,  3.1199,  2.9273,  0.8096, -2.7121,  0.0646, -1.3115,\n",
       "          2.0799,  1.2497, -1.4001, -1.2775,  1.9296, -1.3456,  1.4513, -0.6743,\n",
       "          0.4134,  2.2225, -1.7278,  1.4551,  5.6764, -0.0156,  0.3924,  0.0911,\n",
       "          1.5074, -0.0708, -1.0860, -1.1633,  0.4460, -2.9950, -3.1890, -0.6879,\n",
       "          1.1363,  3.0768, -0.3199, -0.7194, -2.5093, -2.4685,  0.1866, -1.4805,\n",
       "         -0.5201, -0.8099, -0.8224, -1.1065, -2.9313, -1.7303, -1.5416, -0.1286,\n",
       "         -2.0236,  0.7597, -2.1266,  1.0676, -0.7524,  0.0147,  0.4018,  0.6719,\n",
       "         -2.9889,  0.0349, -0.5125, -2.5842, -1.4396,  0.0696,  3.1220, -3.2473,\n",
       "         -0.5900,  0.7667, -0.1190, -1.9254, -1.9178, -1.4155,  0.5542, -0.7370,\n",
       "          2.9042, -1.7957,  0.6115,  2.7282,  1.3623,  0.6691, -0.2338,  3.0963,\n",
       "         -0.0010,  3.7226,  5.8134,  1.9761,  0.2636,  0.3534,  1.3220, -0.0721,\n",
       "          1.3675, -1.2105, -2.4312,  1.3942,  1.5678, -1.5767,  0.3660, -0.7420,\n",
       "         -1.5857, -1.0233, -2.3150,  0.7148, -0.4784, -1.3332, -0.3022,  2.6777]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 7, 7])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([256, 64, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 64, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([64, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([256, 64, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([64, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([256, 64, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 128, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 128, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 128, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 128, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([256, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 256, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([2048, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048, 1024, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([512, 2048, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([2048, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([512, 2048, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3, 3])\n",
      "torch.Size([0])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([2048, 512, 1, 1, 1])\n",
      "torch.Size([0])\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "torch.Size([1000, 2048])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for parameter in i3resnet.parameters():\n",
    "    print(parameter.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dim=3\n",
    "time_padding=0\n",
    "time_stride=1\n",
    "time_dilation=1\n",
    "center=False\n",
    "\n",
    "\n",
    "kernel_dim = (time_dim, conv2d.kernel_size[0], conv2d.kernel_size[1])\n",
    "padding = (time_padding, conv2d.padding[0], conv2d.padding[1])\n",
    "stride = (time_stride, conv2d.stride[0], conv2d.stride[0])\n",
    "dilation = (time_dilation, conv2d.dilation[0], conv2d.dilation[1])\n",
    "conv3d = torch.nn.Conv3d(\n",
    "    conv2d.in_channels,\n",
    "    conv2d.out_channels,\n",
    "    kernel_dim,\n",
    "    padding=padding,\n",
    "    dilation=dilation,\n",
    "    stride=stride)\n",
    "# Repeat filter time_dim times along time dimension\n",
    "weight_2d = conv2d.weight.data\n",
    "if center:\n",
    "    weight_3d = torch.zeros(*weight_2d.shape)\n",
    "    weight_3d = weight_3d.unsqueeze(2).repeat(1, 1, time_dim, 1, 1)\n",
    "    middle_idx = time_dim // 2\n",
    "    weight_3d[:, :, middle_idx, :, :] = weight_2d\n",
    "else:\n",
    "    weight_3d = weight_2d.unsqueeze(2).repeat(1, 1, time_dim, 1, 1)\n",
    "    weight_3d = weight_3d / time_dim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[[ 4.4449e-03,  4.8879e-03, -5.1170e-03,  ...,\n",
       "            -1.3632e-02, -1.4345e-02, -2.3585e-02],\n",
       "           [ 1.3735e-03,  1.9492e-03,  4.9826e-03,  ...,\n",
       "             7.3535e-04, -6.9708e-03, -1.2839e-02],\n",
       "           [ 7.4436e-03,  7.8649e-03,  5.3734e-03,  ...,\n",
       "             3.4270e-02,  2.0880e-02,  1.7326e-02],\n",
       "           ...,\n",
       "           [-3.0116e-04,  9.2558e-03, -3.3684e-03,  ...,\n",
       "            -4.2406e-02, -2.5535e-02,  2.6151e-03],\n",
       "           [ 1.1965e-03,  1.6002e-02,  2.0684e-02,  ...,\n",
       "             8.0890e-03, -1.1221e-02, -5.2363e-03],\n",
       "           [-2.6676e-02, -1.0746e-02, -5.9359e-03,  ...,\n",
       "             1.1786e-02,  7.4796e-03,  5.6923e-04]],\n",
       "\n",
       "          [[ 4.4449e-03,  4.8879e-03, -5.1170e-03,  ...,\n",
       "            -1.3632e-02, -1.4345e-02, -2.3585e-02],\n",
       "           [ 1.3735e-03,  1.9492e-03,  4.9826e-03,  ...,\n",
       "             7.3535e-04, -6.9708e-03, -1.2839e-02],\n",
       "           [ 7.4436e-03,  7.8649e-03,  5.3734e-03,  ...,\n",
       "             3.4270e-02,  2.0880e-02,  1.7326e-02],\n",
       "           ...,\n",
       "           [-3.0116e-04,  9.2558e-03, -3.3684e-03,  ...,\n",
       "            -4.2406e-02, -2.5535e-02,  2.6151e-03],\n",
       "           [ 1.1965e-03,  1.6002e-02,  2.0684e-02,  ...,\n",
       "             8.0890e-03, -1.1221e-02, -5.2363e-03],\n",
       "           [-2.6676e-02, -1.0746e-02, -5.9359e-03,  ...,\n",
       "             1.1786e-02,  7.4796e-03,  5.6923e-04]],\n",
       "\n",
       "          [[ 4.4449e-03,  4.8879e-03, -5.1170e-03,  ...,\n",
       "            -1.3632e-02, -1.4345e-02, -2.3585e-02],\n",
       "           [ 1.3735e-03,  1.9492e-03,  4.9826e-03,  ...,\n",
       "             7.3535e-04, -6.9708e-03, -1.2839e-02],\n",
       "           [ 7.4436e-03,  7.8649e-03,  5.3734e-03,  ...,\n",
       "             3.4270e-02,  2.0880e-02,  1.7326e-02],\n",
       "           ...,\n",
       "           [-3.0116e-04,  9.2558e-03, -3.3684e-03,  ...,\n",
       "            -4.2406e-02, -2.5535e-02,  2.6151e-03],\n",
       "           [ 1.1965e-03,  1.6002e-02,  2.0684e-02,  ...,\n",
       "             8.0890e-03, -1.1221e-02, -5.2363e-03],\n",
       "           [-2.6676e-02, -1.0746e-02, -5.9359e-03,  ...,\n",
       "             1.1786e-02,  7.4796e-03,  5.6923e-04]]],\n",
       "\n",
       "\n",
       "         [[[-6.1507e-03,  3.8049e-03,  7.9501e-03,  ...,\n",
       "             1.7912e-02,  1.4674e-02, -3.1558e-03],\n",
       "           [-2.5758e-03,  6.2966e-03,  2.2660e-02,  ...,\n",
       "             5.3186e-02,  4.8687e-02,  3.9995e-02],\n",
       "           [-1.5338e-02, -2.5358e-02, -2.9883e-02,  ...,\n",
       "             4.0359e-02,  5.5683e-02,  5.8729e-02],\n",
       "           ...,\n",
       "           [ 9.6059e-03,  4.5549e-03, -2.7942e-02,  ...,\n",
       "            -1.2694e-01, -1.0138e-01, -4.6552e-02],\n",
       "           [ 2.7623e-02,  4.6215e-02,  5.0804e-02,  ...,\n",
       "            -1.7077e-03, -4.1451e-02, -4.3224e-02],\n",
       "           [-2.4263e-03,  2.5674e-02,  4.6664e-02,  ...,\n",
       "             6.1423e-02,  3.7146e-02,  7.8126e-03]],\n",
       "\n",
       "          [[-6.1507e-03,  3.8049e-03,  7.9501e-03,  ...,\n",
       "             1.7912e-02,  1.4674e-02, -3.1558e-03],\n",
       "           [-2.5758e-03,  6.2966e-03,  2.2660e-02,  ...,\n",
       "             5.3186e-02,  4.8687e-02,  3.9995e-02],\n",
       "           [-1.5338e-02, -2.5358e-02, -2.9883e-02,  ...,\n",
       "             4.0359e-02,  5.5683e-02,  5.8729e-02],\n",
       "           ...,\n",
       "           [ 9.6059e-03,  4.5549e-03, -2.7942e-02,  ...,\n",
       "            -1.2694e-01, -1.0138e-01, -4.6552e-02],\n",
       "           [ 2.7623e-02,  4.6215e-02,  5.0804e-02,  ...,\n",
       "            -1.7077e-03, -4.1451e-02, -4.3224e-02],\n",
       "           [-2.4263e-03,  2.5674e-02,  4.6664e-02,  ...,\n",
       "             6.1423e-02,  3.7146e-02,  7.8126e-03]],\n",
       "\n",
       "          [[-6.1507e-03,  3.8049e-03,  7.9501e-03,  ...,\n",
       "             1.7912e-02,  1.4674e-02, -3.1558e-03],\n",
       "           [-2.5758e-03,  6.2966e-03,  2.2660e-02,  ...,\n",
       "             5.3186e-02,  4.8687e-02,  3.9995e-02],\n",
       "           [-1.5338e-02, -2.5358e-02, -2.9883e-02,  ...,\n",
       "             4.0359e-02,  5.5683e-02,  5.8729e-02],\n",
       "           ...,\n",
       "           [ 9.6059e-03,  4.5549e-03, -2.7942e-02,  ...,\n",
       "            -1.2694e-01, -1.0138e-01, -4.6552e-02],\n",
       "           [ 2.7623e-02,  4.6215e-02,  5.0804e-02,  ...,\n",
       "            -1.7077e-03, -4.1451e-02, -4.3224e-02],\n",
       "           [-2.4263e-03,  2.5674e-02,  4.6664e-02,  ...,\n",
       "             6.1423e-02,  3.7146e-02,  7.8126e-03]]],\n",
       "\n",
       "\n",
       "         [[[-6.1036e-03, -1.8808e-03,  2.9075e-03,  ...,\n",
       "             8.5918e-03,  8.8102e-03, -1.3305e-03],\n",
       "           [-3.3659e-03,  1.3872e-03,  1.6577e-02,  ...,\n",
       "             4.1488e-02,  3.9834e-02,  3.7328e-02],\n",
       "           [-2.1159e-02, -3.3819e-02, -3.2781e-02,  ...,\n",
       "             3.5435e-02,  4.6605e-02,  4.9806e-02],\n",
       "           ...,\n",
       "           [ 8.6034e-03,  3.5002e-03, -2.4859e-02,  ...,\n",
       "            -1.0462e-01, -8.4983e-02, -4.0921e-02],\n",
       "           [ 2.4350e-02,  3.7233e-02,  4.3644e-02,  ...,\n",
       "            -2.1528e-03, -4.1828e-02, -4.1486e-02],\n",
       "           [-2.1403e-03,  2.2131e-02,  4.0590e-02,  ...,\n",
       "             6.3582e-02,  3.8048e-02,  7.7791e-03]],\n",
       "\n",
       "          [[-6.1036e-03, -1.8808e-03,  2.9075e-03,  ...,\n",
       "             8.5918e-03,  8.8102e-03, -1.3305e-03],\n",
       "           [-3.3659e-03,  1.3872e-03,  1.6577e-02,  ...,\n",
       "             4.1488e-02,  3.9834e-02,  3.7328e-02],\n",
       "           [-2.1159e-02, -3.3819e-02, -3.2781e-02,  ...,\n",
       "             3.5435e-02,  4.6605e-02,  4.9806e-02],\n",
       "           ...,\n",
       "           [ 8.6034e-03,  3.5002e-03, -2.4859e-02,  ...,\n",
       "            -1.0462e-01, -8.4983e-02, -4.0921e-02],\n",
       "           [ 2.4350e-02,  3.7233e-02,  4.3644e-02,  ...,\n",
       "            -2.1528e-03, -4.1828e-02, -4.1486e-02],\n",
       "           [-2.1403e-03,  2.2131e-02,  4.0590e-02,  ...,\n",
       "             6.3582e-02,  3.8048e-02,  7.7791e-03]],\n",
       "\n",
       "          [[-6.1036e-03, -1.8808e-03,  2.9075e-03,  ...,\n",
       "             8.5918e-03,  8.8102e-03, -1.3305e-03],\n",
       "           [-3.3659e-03,  1.3872e-03,  1.6577e-02,  ...,\n",
       "             4.1488e-02,  3.9834e-02,  3.7328e-02],\n",
       "           [-2.1159e-02, -3.3819e-02, -3.2781e-02,  ...,\n",
       "             3.5435e-02,  4.6605e-02,  4.9806e-02],\n",
       "           ...,\n",
       "           [ 8.6034e-03,  3.5002e-03, -2.4859e-02,  ...,\n",
       "            -1.0462e-01, -8.4983e-02, -4.0921e-02],\n",
       "           [ 2.4350e-02,  3.7233e-02,  4.3644e-02,  ...,\n",
       "            -2.1528e-03, -4.1828e-02, -4.1486e-02],\n",
       "           [-2.1403e-03,  2.2131e-02,  4.0590e-02,  ...,\n",
       "             6.3582e-02,  3.8048e-02,  7.7791e-03]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 2.2870e-02,  1.2652e-02,  1.7855e-02,  ...,\n",
       "             8.9636e-03,  1.6123e-02,  2.1088e-02],\n",
       "           [ 2.0615e-02,  6.1355e-03,  7.5575e-03,  ...,\n",
       "            -1.6267e-02, -7.3766e-03, -1.9096e-03],\n",
       "           [ 1.8851e-02,  4.9610e-03, -2.3062e-03,  ...,\n",
       "            -4.3064e-02, -3.1681e-02, -1.9557e-02],\n",
       "           ...,\n",
       "           [ 7.9340e-03, -1.7424e-02, -3.7590e-02,  ...,\n",
       "            -8.5304e-02, -8.0164e-02, -6.7718e-02],\n",
       "           [ 1.8740e-02, -7.2748e-03, -1.9736e-02,  ...,\n",
       "            -7.9353e-02, -6.6121e-02, -5.5259e-02],\n",
       "           [ 1.9878e-02,  1.2391e-03, -1.6239e-02,  ...,\n",
       "            -5.3660e-02, -4.7787e-02, -3.4169e-02]],\n",
       "\n",
       "          [[ 2.2870e-02,  1.2652e-02,  1.7855e-02,  ...,\n",
       "             8.9636e-03,  1.6123e-02,  2.1088e-02],\n",
       "           [ 2.0615e-02,  6.1355e-03,  7.5575e-03,  ...,\n",
       "            -1.6267e-02, -7.3766e-03, -1.9096e-03],\n",
       "           [ 1.8851e-02,  4.9610e-03, -2.3062e-03,  ...,\n",
       "            -4.3064e-02, -3.1681e-02, -1.9557e-02],\n",
       "           ...,\n",
       "           [ 7.9340e-03, -1.7424e-02, -3.7590e-02,  ...,\n",
       "            -8.5304e-02, -8.0164e-02, -6.7718e-02],\n",
       "           [ 1.8740e-02, -7.2748e-03, -1.9736e-02,  ...,\n",
       "            -7.9353e-02, -6.6121e-02, -5.5259e-02],\n",
       "           [ 1.9878e-02,  1.2391e-03, -1.6239e-02,  ...,\n",
       "            -5.3660e-02, -4.7787e-02, -3.4169e-02]],\n",
       "\n",
       "          [[ 2.2870e-02,  1.2652e-02,  1.7855e-02,  ...,\n",
       "             8.9636e-03,  1.6123e-02,  2.1088e-02],\n",
       "           [ 2.0615e-02,  6.1355e-03,  7.5575e-03,  ...,\n",
       "            -1.6267e-02, -7.3766e-03, -1.9096e-03],\n",
       "           [ 1.8851e-02,  4.9610e-03, -2.3062e-03,  ...,\n",
       "            -4.3064e-02, -3.1681e-02, -1.9557e-02],\n",
       "           ...,\n",
       "           [ 7.9340e-03, -1.7424e-02, -3.7590e-02,  ...,\n",
       "            -8.5304e-02, -8.0164e-02, -6.7718e-02],\n",
       "           [ 1.8740e-02, -7.2748e-03, -1.9736e-02,  ...,\n",
       "            -7.9353e-02, -6.6121e-02, -5.5259e-02],\n",
       "           [ 1.9878e-02,  1.2391e-03, -1.6239e-02,  ...,\n",
       "            -5.3660e-02, -4.7787e-02, -3.4169e-02]]],\n",
       "\n",
       "\n",
       "         [[[-3.3014e-02, -2.4043e-02, -2.4249e-02,  ...,\n",
       "            -1.2077e-02, -2.7292e-02, -2.9373e-02],\n",
       "           [-2.3540e-02, -1.3067e-02, -3.5046e-03,  ...,\n",
       "             1.9840e-02,  8.6302e-03, -4.4289e-03],\n",
       "           [-3.1321e-02, -8.4392e-03,  1.0242e-02,  ...,\n",
       "             6.9126e-02,  5.3872e-02,  2.8955e-02],\n",
       "           ...,\n",
       "           [-1.3326e-02,  2.1383e-02,  5.6470e-02,  ...,\n",
       "             1.5271e-01,  1.2613e-01,  8.6232e-02],\n",
       "           [-2.1662e-02,  4.5458e-03,  4.3361e-02,  ...,\n",
       "             1.2220e-01,  1.0670e-01,  6.8140e-02],\n",
       "           [-3.4777e-02, -9.0719e-03,  1.3733e-02,  ...,\n",
       "             7.5991e-02,  6.2072e-02,  3.9514e-02]],\n",
       "\n",
       "          [[-3.3014e-02, -2.4043e-02, -2.4249e-02,  ...,\n",
       "            -1.2077e-02, -2.7292e-02, -2.9373e-02],\n",
       "           [-2.3540e-02, -1.3067e-02, -3.5046e-03,  ...,\n",
       "             1.9840e-02,  8.6302e-03, -4.4289e-03],\n",
       "           [-3.1321e-02, -8.4392e-03,  1.0242e-02,  ...,\n",
       "             6.9126e-02,  5.3872e-02,  2.8955e-02],\n",
       "           ...,\n",
       "           [-1.3326e-02,  2.1383e-02,  5.6470e-02,  ...,\n",
       "             1.5271e-01,  1.2613e-01,  8.6232e-02],\n",
       "           [-2.1662e-02,  4.5458e-03,  4.3361e-02,  ...,\n",
       "             1.2220e-01,  1.0670e-01,  6.8140e-02],\n",
       "           [-3.4777e-02, -9.0719e-03,  1.3733e-02,  ...,\n",
       "             7.5991e-02,  6.2072e-02,  3.9514e-02]],\n",
       "\n",
       "          [[-3.3014e-02, -2.4043e-02, -2.4249e-02,  ...,\n",
       "            -1.2077e-02, -2.7292e-02, -2.9373e-02],\n",
       "           [-2.3540e-02, -1.3067e-02, -3.5046e-03,  ...,\n",
       "             1.9840e-02,  8.6302e-03, -4.4289e-03],\n",
       "           [-3.1321e-02, -8.4392e-03,  1.0242e-02,  ...,\n",
       "             6.9126e-02,  5.3872e-02,  2.8955e-02],\n",
       "           ...,\n",
       "           [-1.3326e-02,  2.1383e-02,  5.6470e-02,  ...,\n",
       "             1.5271e-01,  1.2613e-01,  8.6232e-02],\n",
       "           [-2.1662e-02,  4.5458e-03,  4.3361e-02,  ...,\n",
       "             1.2220e-01,  1.0670e-01,  6.8140e-02],\n",
       "           [-3.4777e-02, -9.0719e-03,  1.3733e-02,  ...,\n",
       "             7.5991e-02,  6.2072e-02,  3.9514e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.4239e-02,  1.5756e-02,  5.9326e-03,  ...,\n",
       "             1.1564e-02,  9.5316e-03,  1.4391e-02],\n",
       "           [ 1.2103e-02,  1.1153e-02, -4.1496e-04,  ...,\n",
       "             1.4303e-03,  1.5504e-03,  8.3206e-03],\n",
       "           [ 7.8470e-03,  5.6086e-03, -5.1085e-03,  ...,\n",
       "            -2.4288e-02, -2.4010e-02, -7.9156e-03],\n",
       "           ...,\n",
       "           [ 9.8744e-03,  6.0588e-04, -2.6520e-02,  ...,\n",
       "            -6.0460e-02, -5.6501e-02, -2.0397e-02],\n",
       "           [ 1.1744e-02, -2.8432e-03, -1.8084e-02,  ...,\n",
       "            -5.0227e-02, -4.2491e-02, -1.5113e-02],\n",
       "           [ 1.8262e-02,  1.3268e-02, -3.4909e-03,  ...,\n",
       "            -1.4111e-02, -1.7407e-02,  1.7092e-04]],\n",
       "\n",
       "          [[ 1.4239e-02,  1.5756e-02,  5.9326e-03,  ...,\n",
       "             1.1564e-02,  9.5316e-03,  1.4391e-02],\n",
       "           [ 1.2103e-02,  1.1153e-02, -4.1496e-04,  ...,\n",
       "             1.4303e-03,  1.5504e-03,  8.3206e-03],\n",
       "           [ 7.8470e-03,  5.6086e-03, -5.1085e-03,  ...,\n",
       "            -2.4288e-02, -2.4010e-02, -7.9156e-03],\n",
       "           ...,\n",
       "           [ 9.8744e-03,  6.0588e-04, -2.6520e-02,  ...,\n",
       "            -6.0460e-02, -5.6501e-02, -2.0397e-02],\n",
       "           [ 1.1744e-02, -2.8432e-03, -1.8084e-02,  ...,\n",
       "            -5.0227e-02, -4.2491e-02, -1.5113e-02],\n",
       "           [ 1.8262e-02,  1.3268e-02, -3.4909e-03,  ...,\n",
       "            -1.4111e-02, -1.7407e-02,  1.7092e-04]],\n",
       "\n",
       "          [[ 1.4239e-02,  1.5756e-02,  5.9326e-03,  ...,\n",
       "             1.1564e-02,  9.5316e-03,  1.4391e-02],\n",
       "           [ 1.2103e-02,  1.1153e-02, -4.1496e-04,  ...,\n",
       "             1.4303e-03,  1.5504e-03,  8.3206e-03],\n",
       "           [ 7.8470e-03,  5.6086e-03, -5.1085e-03,  ...,\n",
       "            -2.4288e-02, -2.4010e-02, -7.9156e-03],\n",
       "           ...,\n",
       "           [ 9.8744e-03,  6.0588e-04, -2.6520e-02,  ...,\n",
       "            -6.0460e-02, -5.6501e-02, -2.0397e-02],\n",
       "           [ 1.1744e-02, -2.8432e-03, -1.8084e-02,  ...,\n",
       "            -5.0227e-02, -4.2491e-02, -1.5113e-02],\n",
       "           [ 1.8262e-02,  1.3268e-02, -3.4909e-03,  ...,\n",
       "            -1.4111e-02, -1.7407e-02,  1.7092e-04]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 2.4351e-03,  5.2286e-03, -8.1409e-05,  ...,\n",
       "            -1.0846e-02, -1.0432e-02, -1.0083e-02],\n",
       "           [ 2.8792e-03,  8.2073e-03,  3.7495e-03,  ...,\n",
       "            -3.5484e-03, -5.0087e-03, -1.1364e-02],\n",
       "           [ 2.5987e-03,  1.0446e-02,  8.3696e-03,  ...,\n",
       "             4.1713e-03, -1.9255e-04, -1.7835e-03],\n",
       "           ...,\n",
       "           [-3.5324e-04,  4.4651e-03,  3.8255e-04,  ...,\n",
       "             1.2196e-02,  1.5597e-02,  2.5073e-02],\n",
       "           [-5.0911e-03,  2.7002e-03, -2.4461e-04,  ...,\n",
       "             1.2441e-03,  6.6011e-03,  2.4989e-02],\n",
       "           [-6.5472e-03, -6.1809e-04, -2.3028e-03,  ...,\n",
       "            -1.0999e-03,  9.6573e-03,  2.9186e-02]],\n",
       "\n",
       "          [[ 2.4351e-03,  5.2286e-03, -8.1409e-05,  ...,\n",
       "            -1.0846e-02, -1.0432e-02, -1.0083e-02],\n",
       "           [ 2.8792e-03,  8.2073e-03,  3.7495e-03,  ...,\n",
       "            -3.5484e-03, -5.0087e-03, -1.1364e-02],\n",
       "           [ 2.5987e-03,  1.0446e-02,  8.3696e-03,  ...,\n",
       "             4.1713e-03, -1.9255e-04, -1.7835e-03],\n",
       "           ...,\n",
       "           [-3.5324e-04,  4.4651e-03,  3.8255e-04,  ...,\n",
       "             1.2196e-02,  1.5597e-02,  2.5073e-02],\n",
       "           [-5.0911e-03,  2.7002e-03, -2.4461e-04,  ...,\n",
       "             1.2441e-03,  6.6011e-03,  2.4989e-02],\n",
       "           [-6.5472e-03, -6.1809e-04, -2.3028e-03,  ...,\n",
       "            -1.0999e-03,  9.6573e-03,  2.9186e-02]],\n",
       "\n",
       "          [[ 2.4351e-03,  5.2286e-03, -8.1409e-05,  ...,\n",
       "            -1.0846e-02, -1.0432e-02, -1.0083e-02],\n",
       "           [ 2.8792e-03,  8.2073e-03,  3.7495e-03,  ...,\n",
       "            -3.5484e-03, -5.0087e-03, -1.1364e-02],\n",
       "           [ 2.5987e-03,  1.0446e-02,  8.3696e-03,  ...,\n",
       "             4.1713e-03, -1.9255e-04, -1.7835e-03],\n",
       "           ...,\n",
       "           [-3.5324e-04,  4.4651e-03,  3.8255e-04,  ...,\n",
       "             1.2196e-02,  1.5597e-02,  2.5073e-02],\n",
       "           [-5.0911e-03,  2.7002e-03, -2.4461e-04,  ...,\n",
       "             1.2441e-03,  6.6011e-03,  2.4989e-02],\n",
       "           [-6.5472e-03, -6.1809e-04, -2.3028e-03,  ...,\n",
       "            -1.0999e-03,  9.6573e-03,  2.9186e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.2583e-03,  2.9500e-03,  7.7538e-04,  ...,\n",
       "             4.5137e-03,  1.2016e-02,  1.6133e-02],\n",
       "           [ 4.7176e-03,  3.8947e-03, -9.8803e-04,  ...,\n",
       "             9.0563e-03,  1.7284e-02,  1.2897e-02],\n",
       "           [ 1.0661e-03,  1.6950e-03, -3.1090e-03,  ...,\n",
       "             1.3712e-02,  1.8183e-02,  1.5031e-02],\n",
       "           ...,\n",
       "           [-5.6784e-03, -1.4289e-02, -2.8213e-02,  ...,\n",
       "            -1.6416e-02, -7.9672e-03,  8.7441e-04],\n",
       "           [-9.3849e-04, -2.9457e-03, -1.6027e-02,  ...,\n",
       "            -2.8811e-02, -2.3882e-02, -7.7994e-03],\n",
       "           [ 9.5960e-03,  7.6668e-03, -1.5626e-03,  ...,\n",
       "            -1.6925e-02, -1.3152e-02, -2.3711e-03]],\n",
       "\n",
       "          [[ 4.2583e-03,  2.9500e-03,  7.7538e-04,  ...,\n",
       "             4.5137e-03,  1.2016e-02,  1.6133e-02],\n",
       "           [ 4.7176e-03,  3.8947e-03, -9.8803e-04,  ...,\n",
       "             9.0563e-03,  1.7284e-02,  1.2897e-02],\n",
       "           [ 1.0661e-03,  1.6950e-03, -3.1090e-03,  ...,\n",
       "             1.3712e-02,  1.8183e-02,  1.5031e-02],\n",
       "           ...,\n",
       "           [-5.6784e-03, -1.4289e-02, -2.8213e-02,  ...,\n",
       "            -1.6416e-02, -7.9672e-03,  8.7441e-04],\n",
       "           [-9.3849e-04, -2.9457e-03, -1.6027e-02,  ...,\n",
       "            -2.8811e-02, -2.3882e-02, -7.7994e-03],\n",
       "           [ 9.5960e-03,  7.6668e-03, -1.5626e-03,  ...,\n",
       "            -1.6925e-02, -1.3152e-02, -2.3711e-03]],\n",
       "\n",
       "          [[ 4.2583e-03,  2.9500e-03,  7.7538e-04,  ...,\n",
       "             4.5137e-03,  1.2016e-02,  1.6133e-02],\n",
       "           [ 4.7176e-03,  3.8947e-03, -9.8803e-04,  ...,\n",
       "             9.0563e-03,  1.7284e-02,  1.2897e-02],\n",
       "           [ 1.0661e-03,  1.6950e-03, -3.1090e-03,  ...,\n",
       "             1.3712e-02,  1.8183e-02,  1.5031e-02],\n",
       "           ...,\n",
       "           [-5.6784e-03, -1.4289e-02, -2.8213e-02,  ...,\n",
       "            -1.6416e-02, -7.9672e-03,  8.7441e-04],\n",
       "           [-9.3849e-04, -2.9457e-03, -1.6027e-02,  ...,\n",
       "            -2.8811e-02, -2.3882e-02, -7.7994e-03],\n",
       "           [ 9.5960e-03,  7.6668e-03, -1.5626e-03,  ...,\n",
       "            -1.6925e-02, -1.3152e-02, -2.3711e-03]]],\n",
       "\n",
       "\n",
       "         [[[ 3.1170e-03, -1.2013e-02, -1.0577e-02,  ...,\n",
       "             1.1615e-03,  1.4399e-02,  1.5028e-02],\n",
       "           [-3.9584e-03, -1.9421e-02, -2.1001e-02,  ...,\n",
       "            -5.8912e-03,  5.2947e-03, -2.5518e-03],\n",
       "           [ 4.7384e-03, -1.1268e-02, -1.6699e-02,  ...,\n",
       "            -7.1220e-04,  2.0175e-03, -2.6709e-03],\n",
       "           ...,\n",
       "           [ 2.6943e-03, -1.6639e-02, -3.0084e-02,  ...,\n",
       "            -2.9188e-02, -3.3156e-02, -3.6413e-02],\n",
       "           [ 6.2605e-03, -4.7889e-03, -1.5569e-02,  ...,\n",
       "            -3.7290e-02, -4.8382e-02, -4.8147e-02],\n",
       "           [ 1.9268e-02,  5.7507e-03, -1.9256e-03,  ...,\n",
       "            -2.4805e-02, -3.7709e-02, -4.1447e-02]],\n",
       "\n",
       "          [[ 3.1170e-03, -1.2013e-02, -1.0577e-02,  ...,\n",
       "             1.1615e-03,  1.4399e-02,  1.5028e-02],\n",
       "           [-3.9584e-03, -1.9421e-02, -2.1001e-02,  ...,\n",
       "            -5.8912e-03,  5.2947e-03, -2.5518e-03],\n",
       "           [ 4.7384e-03, -1.1268e-02, -1.6699e-02,  ...,\n",
       "            -7.1220e-04,  2.0175e-03, -2.6709e-03],\n",
       "           ...,\n",
       "           [ 2.6943e-03, -1.6639e-02, -3.0084e-02,  ...,\n",
       "            -2.9188e-02, -3.3156e-02, -3.6413e-02],\n",
       "           [ 6.2605e-03, -4.7889e-03, -1.5569e-02,  ...,\n",
       "            -3.7290e-02, -4.8382e-02, -4.8147e-02],\n",
       "           [ 1.9268e-02,  5.7507e-03, -1.9256e-03,  ...,\n",
       "            -2.4805e-02, -3.7709e-02, -4.1447e-02]],\n",
       "\n",
       "          [[ 3.1170e-03, -1.2013e-02, -1.0577e-02,  ...,\n",
       "             1.1615e-03,  1.4399e-02,  1.5028e-02],\n",
       "           [-3.9584e-03, -1.9421e-02, -2.1001e-02,  ...,\n",
       "            -5.8912e-03,  5.2947e-03, -2.5518e-03],\n",
       "           [ 4.7384e-03, -1.1268e-02, -1.6699e-02,  ...,\n",
       "            -7.1220e-04,  2.0175e-03, -2.6709e-03],\n",
       "           ...,\n",
       "           [ 2.6943e-03, -1.6639e-02, -3.0084e-02,  ...,\n",
       "            -2.9188e-02, -3.3156e-02, -3.6413e-02],\n",
       "           [ 6.2605e-03, -4.7889e-03, -1.5569e-02,  ...,\n",
       "            -3.7290e-02, -4.8382e-02, -4.8147e-02],\n",
       "           [ 1.9268e-02,  5.7507e-03, -1.9256e-03,  ...,\n",
       "            -2.4805e-02, -3.7709e-02, -4.1447e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 5.2130e-03,  6.8036e-03,  1.1906e-02,  ...,\n",
       "             2.3859e-03,  1.5164e-02, -2.5511e-03],\n",
       "           [-7.2816e-03,  1.8710e-02,  2.0221e-02,  ...,\n",
       "            -1.8969e-02,  2.8390e-02, -8.8877e-03],\n",
       "           [-1.5860e-02,  3.5631e-02,  2.5222e-02,  ...,\n",
       "            -2.9335e-02,  5.0530e-02, -1.0691e-02],\n",
       "           ...,\n",
       "           [ 4.9247e-04,  4.1846e-02, -1.6428e-02,  ...,\n",
       "             1.9700e-02,  5.2519e-02, -1.3722e-02],\n",
       "           [ 1.6728e-03,  2.0856e-02, -1.9584e-02,  ...,\n",
       "             1.5767e-02,  2.7455e-02, -1.5339e-02],\n",
       "           [ 5.4004e-03,  1.8016e-03, -2.1950e-02,  ...,\n",
       "             1.7000e-02,  1.5490e-02, -5.5862e-03]],\n",
       "\n",
       "          [[ 5.2130e-03,  6.8036e-03,  1.1906e-02,  ...,\n",
       "             2.3859e-03,  1.5164e-02, -2.5511e-03],\n",
       "           [-7.2816e-03,  1.8710e-02,  2.0221e-02,  ...,\n",
       "            -1.8969e-02,  2.8390e-02, -8.8877e-03],\n",
       "           [-1.5860e-02,  3.5631e-02,  2.5222e-02,  ...,\n",
       "            -2.9335e-02,  5.0530e-02, -1.0691e-02],\n",
       "           ...,\n",
       "           [ 4.9247e-04,  4.1846e-02, -1.6428e-02,  ...,\n",
       "             1.9700e-02,  5.2519e-02, -1.3722e-02],\n",
       "           [ 1.6728e-03,  2.0856e-02, -1.9584e-02,  ...,\n",
       "             1.5767e-02,  2.7455e-02, -1.5339e-02],\n",
       "           [ 5.4004e-03,  1.8016e-03, -2.1950e-02,  ...,\n",
       "             1.7000e-02,  1.5490e-02, -5.5862e-03]],\n",
       "\n",
       "          [[ 5.2130e-03,  6.8036e-03,  1.1906e-02,  ...,\n",
       "             2.3859e-03,  1.5164e-02, -2.5511e-03],\n",
       "           [-7.2816e-03,  1.8710e-02,  2.0221e-02,  ...,\n",
       "            -1.8969e-02,  2.8390e-02, -8.8877e-03],\n",
       "           [-1.5860e-02,  3.5631e-02,  2.5222e-02,  ...,\n",
       "            -2.9335e-02,  5.0530e-02, -1.0691e-02],\n",
       "           ...,\n",
       "           [ 4.9247e-04,  4.1846e-02, -1.6428e-02,  ...,\n",
       "             1.9700e-02,  5.2519e-02, -1.3722e-02],\n",
       "           [ 1.6728e-03,  2.0856e-02, -1.9584e-02,  ...,\n",
       "             1.5767e-02,  2.7455e-02, -1.5339e-02],\n",
       "           [ 5.4004e-03,  1.8016e-03, -2.1950e-02,  ...,\n",
       "             1.7000e-02,  1.5490e-02, -5.5862e-03]]],\n",
       "\n",
       "\n",
       "         [[[ 3.4000e-03,  1.4864e-02,  5.1070e-04,  ...,\n",
       "            -2.2182e-02,  1.5244e-02,  1.6176e-02],\n",
       "           [ 1.5029e-03,  4.2911e-02,  1.0050e-02,  ...,\n",
       "            -4.8808e-02,  4.9144e-02,  2.7913e-02],\n",
       "           [ 1.8708e-03,  7.2485e-02,  1.0311e-02,  ...,\n",
       "            -6.0111e-02,  8.7041e-02,  3.1402e-02],\n",
       "           ...,\n",
       "           [ 1.5483e-02,  6.4868e-02, -4.6310e-02,  ...,\n",
       "             1.4609e-02,  9.5255e-02,  1.7227e-02],\n",
       "           [ 8.4815e-03,  3.1467e-02, -4.5323e-02,  ...,\n",
       "             1.8511e-02,  5.2357e-02, -4.6462e-03],\n",
       "           [ 5.4116e-03,  9.7475e-03, -3.5047e-02,  ...,\n",
       "             2.4187e-02,  2.7482e-02, -3.4831e-03]],\n",
       "\n",
       "          [[ 3.4000e-03,  1.4864e-02,  5.1070e-04,  ...,\n",
       "            -2.2182e-02,  1.5244e-02,  1.6176e-02],\n",
       "           [ 1.5029e-03,  4.2911e-02,  1.0050e-02,  ...,\n",
       "            -4.8808e-02,  4.9144e-02,  2.7913e-02],\n",
       "           [ 1.8708e-03,  7.2485e-02,  1.0311e-02,  ...,\n",
       "            -6.0111e-02,  8.7041e-02,  3.1402e-02],\n",
       "           ...,\n",
       "           [ 1.5483e-02,  6.4868e-02, -4.6310e-02,  ...,\n",
       "             1.4609e-02,  9.5255e-02,  1.7227e-02],\n",
       "           [ 8.4815e-03,  3.1467e-02, -4.5323e-02,  ...,\n",
       "             1.8511e-02,  5.2357e-02, -4.6462e-03],\n",
       "           [ 5.4116e-03,  9.7475e-03, -3.5047e-02,  ...,\n",
       "             2.4187e-02,  2.7482e-02, -3.4831e-03]],\n",
       "\n",
       "          [[ 3.4000e-03,  1.4864e-02,  5.1070e-04,  ...,\n",
       "            -2.2182e-02,  1.5244e-02,  1.6176e-02],\n",
       "           [ 1.5029e-03,  4.2911e-02,  1.0050e-02,  ...,\n",
       "            -4.8808e-02,  4.9144e-02,  2.7913e-02],\n",
       "           [ 1.8708e-03,  7.2485e-02,  1.0311e-02,  ...,\n",
       "            -6.0111e-02,  8.7041e-02,  3.1402e-02],\n",
       "           ...,\n",
       "           [ 1.5483e-02,  6.4868e-02, -4.6310e-02,  ...,\n",
       "             1.4609e-02,  9.5255e-02,  1.7227e-02],\n",
       "           [ 8.4815e-03,  3.1467e-02, -4.5323e-02,  ...,\n",
       "             1.8511e-02,  5.2357e-02, -4.6462e-03],\n",
       "           [ 5.4116e-03,  9.7475e-03, -3.5047e-02,  ...,\n",
       "             2.4187e-02,  2.7482e-02, -3.4831e-03]]],\n",
       "\n",
       "\n",
       "         [[[ 2.5437e-04,  7.3471e-03,  4.0095e-03,  ...,\n",
       "            -1.3105e-02,  2.6255e-03,  3.7796e-03],\n",
       "           [-8.9146e-03,  2.5349e-02,  2.1717e-02,  ...,\n",
       "            -1.7836e-02,  2.5862e-02,  5.1535e-03],\n",
       "           [-1.4384e-02,  4.1476e-02,  2.6194e-02,  ...,\n",
       "            -2.4121e-02,  4.5559e-02, -1.2555e-03],\n",
       "           ...,\n",
       "           [-1.6325e-03,  4.0572e-02, -1.6664e-02,  ...,\n",
       "             1.3605e-02,  4.2615e-02, -9.0882e-03],\n",
       "           [-1.9277e-03,  2.2037e-02, -1.6595e-02,  ...,\n",
       "             1.2829e-02,  2.3170e-02, -1.4635e-02],\n",
       "           [ 1.1272e-03,  1.0995e-02, -1.4233e-02,  ...,\n",
       "             1.4480e-02,  1.1156e-02, -9.9928e-03]],\n",
       "\n",
       "          [[ 2.5437e-04,  7.3471e-03,  4.0095e-03,  ...,\n",
       "            -1.3105e-02,  2.6255e-03,  3.7796e-03],\n",
       "           [-8.9146e-03,  2.5349e-02,  2.1717e-02,  ...,\n",
       "            -1.7836e-02,  2.5862e-02,  5.1535e-03],\n",
       "           [-1.4384e-02,  4.1476e-02,  2.6194e-02,  ...,\n",
       "            -2.4121e-02,  4.5559e-02, -1.2555e-03],\n",
       "           ...,\n",
       "           [-1.6325e-03,  4.0572e-02, -1.6664e-02,  ...,\n",
       "             1.3605e-02,  4.2615e-02, -9.0882e-03],\n",
       "           [-1.9277e-03,  2.2037e-02, -1.6595e-02,  ...,\n",
       "             1.2829e-02,  2.3170e-02, -1.4635e-02],\n",
       "           [ 1.1272e-03,  1.0995e-02, -1.4233e-02,  ...,\n",
       "             1.4480e-02,  1.1156e-02, -9.9928e-03]],\n",
       "\n",
       "          [[ 2.5437e-04,  7.3471e-03,  4.0095e-03,  ...,\n",
       "            -1.3105e-02,  2.6255e-03,  3.7796e-03],\n",
       "           [-8.9146e-03,  2.5349e-02,  2.1717e-02,  ...,\n",
       "            -1.7836e-02,  2.5862e-02,  5.1535e-03],\n",
       "           [-1.4384e-02,  4.1476e-02,  2.6194e-02,  ...,\n",
       "            -2.4121e-02,  4.5559e-02, -1.2555e-03],\n",
       "           ...,\n",
       "           [-1.6325e-03,  4.0572e-02, -1.6664e-02,  ...,\n",
       "             1.3605e-02,  4.2615e-02, -9.0882e-03],\n",
       "           [-1.9277e-03,  2.2037e-02, -1.6595e-02,  ...,\n",
       "             1.2829e-02,  2.3170e-02, -1.4635e-02],\n",
       "           [ 1.1272e-03,  1.0995e-02, -1.4233e-02,  ...,\n",
       "             1.4480e-02,  1.1156e-02, -9.9928e-03]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.5281e-02,  1.7437e-02,  1.4976e-02,  ...,\n",
       "            -9.8034e-03,  1.5169e-03,  4.7914e-03],\n",
       "           [ 1.7493e-02,  1.7072e-02,  1.5987e-02,  ...,\n",
       "            -3.7580e-02, -2.7487e-02, -8.5065e-03],\n",
       "           [ 3.0093e-02,  2.5782e-02,  2.2419e-02,  ...,\n",
       "            -7.1507e-02, -3.7152e-02, -5.7257e-03],\n",
       "           ...,\n",
       "           [ 1.0911e-02,  2.3831e-05, -5.1137e-02,  ...,\n",
       "            -8.5122e-02, -3.8157e-02,  1.4028e-02],\n",
       "           [ 6.4096e-03, -9.2900e-03, -4.9296e-02,  ...,\n",
       "            -8.2903e-02, -1.0066e-02,  2.7451e-02],\n",
       "           [-2.2034e-03, -1.9076e-02, -5.0484e-02,  ...,\n",
       "            -6.2271e-02,  3.2593e-03,  3.2790e-02]],\n",
       "\n",
       "          [[ 1.5281e-02,  1.7437e-02,  1.4976e-02,  ...,\n",
       "            -9.8034e-03,  1.5169e-03,  4.7914e-03],\n",
       "           [ 1.7493e-02,  1.7072e-02,  1.5987e-02,  ...,\n",
       "            -3.7580e-02, -2.7487e-02, -8.5065e-03],\n",
       "           [ 3.0093e-02,  2.5782e-02,  2.2419e-02,  ...,\n",
       "            -7.1507e-02, -3.7152e-02, -5.7257e-03],\n",
       "           ...,\n",
       "           [ 1.0911e-02,  2.3831e-05, -5.1137e-02,  ...,\n",
       "            -8.5122e-02, -3.8157e-02,  1.4028e-02],\n",
       "           [ 6.4096e-03, -9.2900e-03, -4.9296e-02,  ...,\n",
       "            -8.2903e-02, -1.0066e-02,  2.7451e-02],\n",
       "           [-2.2034e-03, -1.9076e-02, -5.0484e-02,  ...,\n",
       "            -6.2271e-02,  3.2593e-03,  3.2790e-02]],\n",
       "\n",
       "          [[ 1.5281e-02,  1.7437e-02,  1.4976e-02,  ...,\n",
       "            -9.8034e-03,  1.5169e-03,  4.7914e-03],\n",
       "           [ 1.7493e-02,  1.7072e-02,  1.5987e-02,  ...,\n",
       "            -3.7580e-02, -2.7487e-02, -8.5065e-03],\n",
       "           [ 3.0093e-02,  2.5782e-02,  2.2419e-02,  ...,\n",
       "            -7.1507e-02, -3.7152e-02, -5.7257e-03],\n",
       "           ...,\n",
       "           [ 1.0911e-02,  2.3831e-05, -5.1137e-02,  ...,\n",
       "            -8.5122e-02, -3.8157e-02,  1.4028e-02],\n",
       "           [ 6.4096e-03, -9.2900e-03, -4.9296e-02,  ...,\n",
       "            -8.2903e-02, -1.0066e-02,  2.7451e-02],\n",
       "           [-2.2034e-03, -1.9076e-02, -5.0484e-02,  ...,\n",
       "            -6.2271e-02,  3.2593e-03,  3.2790e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.0361e-03,  4.0008e-03,  5.6395e-03,  ...,\n",
       "             1.5933e-03,  1.5956e-03, -2.8554e-04],\n",
       "           [ 6.5165e-03,  5.0621e-03,  1.1570e-02,  ...,\n",
       "            -1.4215e-03, -4.4331e-03, -1.7225e-03],\n",
       "           [ 6.7404e-03,  3.7272e-03,  1.6851e-02,  ...,\n",
       "            -2.1812e-02, -2.1380e-03,  6.1876e-03],\n",
       "           ...,\n",
       "           [-3.7098e-03,  3.5430e-03, -1.4142e-02,  ...,\n",
       "            -1.6061e-02, -9.4154e-03,  1.5475e-02],\n",
       "           [ 2.5218e-03,  3.7696e-03, -4.5116e-03,  ...,\n",
       "            -2.2213e-02,  3.4885e-03,  1.2088e-02],\n",
       "           [ 3.2831e-03,  2.1257e-03, -5.2569e-05,  ...,\n",
       "            -1.0289e-02,  8.8413e-03,  1.0030e-02]],\n",
       "\n",
       "          [[-1.0361e-03,  4.0008e-03,  5.6395e-03,  ...,\n",
       "             1.5933e-03,  1.5956e-03, -2.8554e-04],\n",
       "           [ 6.5165e-03,  5.0621e-03,  1.1570e-02,  ...,\n",
       "            -1.4215e-03, -4.4331e-03, -1.7225e-03],\n",
       "           [ 6.7404e-03,  3.7272e-03,  1.6851e-02,  ...,\n",
       "            -2.1812e-02, -2.1380e-03,  6.1876e-03],\n",
       "           ...,\n",
       "           [-3.7098e-03,  3.5430e-03, -1.4142e-02,  ...,\n",
       "            -1.6061e-02, -9.4154e-03,  1.5475e-02],\n",
       "           [ 2.5218e-03,  3.7696e-03, -4.5116e-03,  ...,\n",
       "            -2.2213e-02,  3.4885e-03,  1.2088e-02],\n",
       "           [ 3.2831e-03,  2.1257e-03, -5.2569e-05,  ...,\n",
       "            -1.0289e-02,  8.8413e-03,  1.0030e-02]],\n",
       "\n",
       "          [[-1.0361e-03,  4.0008e-03,  5.6395e-03,  ...,\n",
       "             1.5933e-03,  1.5956e-03, -2.8554e-04],\n",
       "           [ 6.5165e-03,  5.0621e-03,  1.1570e-02,  ...,\n",
       "            -1.4215e-03, -4.4331e-03, -1.7225e-03],\n",
       "           [ 6.7404e-03,  3.7272e-03,  1.6851e-02,  ...,\n",
       "            -2.1812e-02, -2.1380e-03,  6.1876e-03],\n",
       "           ...,\n",
       "           [-3.7098e-03,  3.5430e-03, -1.4142e-02,  ...,\n",
       "            -1.6061e-02, -9.4154e-03,  1.5475e-02],\n",
       "           [ 2.5218e-03,  3.7696e-03, -4.5116e-03,  ...,\n",
       "            -2.2213e-02,  3.4885e-03,  1.2088e-02],\n",
       "           [ 3.2831e-03,  2.1257e-03, -5.2569e-05,  ...,\n",
       "            -1.0289e-02,  8.8413e-03,  1.0030e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.4139e-02, -7.7329e-03, -7.4927e-03,  ...,\n",
       "             4.8871e-03,  4.0510e-03, -7.0412e-03],\n",
       "           [-9.8080e-03, -8.5533e-03,  4.9528e-04,  ...,\n",
       "             1.4251e-02,  7.1770e-03, -1.8694e-03],\n",
       "           [-1.3155e-02, -1.5019e-02,  4.9918e-03,  ...,\n",
       "             1.0213e-02,  1.3813e-02, -2.5833e-03],\n",
       "           ...,\n",
       "           [-1.0417e-02,  2.5905e-03,  5.3177e-03,  ...,\n",
       "             2.1062e-02,  1.6186e-03, -9.9374e-03],\n",
       "           [-4.3102e-03,  5.5965e-03,  1.6145e-02,  ...,\n",
       "             1.5434e-02,  8.8629e-03, -1.3876e-02],\n",
       "           [-5.7126e-03,  2.4191e-03,  1.6076e-02,  ...,\n",
       "             1.1793e-02,  4.8001e-03, -1.5754e-02]],\n",
       "\n",
       "          [[-1.4139e-02, -7.7329e-03, -7.4927e-03,  ...,\n",
       "             4.8871e-03,  4.0510e-03, -7.0412e-03],\n",
       "           [-9.8080e-03, -8.5533e-03,  4.9528e-04,  ...,\n",
       "             1.4251e-02,  7.1770e-03, -1.8694e-03],\n",
       "           [-1.3155e-02, -1.5019e-02,  4.9918e-03,  ...,\n",
       "             1.0213e-02,  1.3813e-02, -2.5833e-03],\n",
       "           ...,\n",
       "           [-1.0417e-02,  2.5905e-03,  5.3177e-03,  ...,\n",
       "             2.1062e-02,  1.6186e-03, -9.9374e-03],\n",
       "           [-4.3102e-03,  5.5965e-03,  1.6145e-02,  ...,\n",
       "             1.5434e-02,  8.8629e-03, -1.3876e-02],\n",
       "           [-5.7126e-03,  2.4191e-03,  1.6076e-02,  ...,\n",
       "             1.1793e-02,  4.8001e-03, -1.5754e-02]],\n",
       "\n",
       "          [[-1.4139e-02, -7.7329e-03, -7.4927e-03,  ...,\n",
       "             4.8871e-03,  4.0510e-03, -7.0412e-03],\n",
       "           [-9.8080e-03, -8.5533e-03,  4.9528e-04,  ...,\n",
       "             1.4251e-02,  7.1770e-03, -1.8694e-03],\n",
       "           [-1.3155e-02, -1.5019e-02,  4.9918e-03,  ...,\n",
       "             1.0213e-02,  1.3813e-02, -2.5833e-03],\n",
       "           ...,\n",
       "           [-1.0417e-02,  2.5905e-03,  5.3177e-03,  ...,\n",
       "             2.1062e-02,  1.6186e-03, -9.9374e-03],\n",
       "           [-4.3102e-03,  5.5965e-03,  1.6145e-02,  ...,\n",
       "             1.5434e-02,  8.8629e-03, -1.3876e-02],\n",
       "           [-5.7126e-03,  2.4191e-03,  1.6076e-02,  ...,\n",
       "             1.1793e-02,  4.8001e-03, -1.5754e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 6.6121e-03, -9.4386e-03,  2.0548e-02,  ...,\n",
       "            -1.7568e-02,  3.2777e-03,  1.6559e-03],\n",
       "           [-1.5395e-02,  1.7907e-02, -8.8572e-03,  ...,\n",
       "             6.3842e-03, -7.3438e-03, -4.4029e-03],\n",
       "           [ 1.7646e-02, -1.4741e-02, -1.2486e-02,  ...,\n",
       "            -7.1227e-02, -7.2066e-04,  1.1478e-02],\n",
       "           ...,\n",
       "           [-1.1896e-02,  3.1222e-02,  3.9697e-02,  ...,\n",
       "             1.7477e-01, -1.5124e-02, -1.9732e-02],\n",
       "           [-3.8018e-03,  3.3597e-02, -6.6162e-02,  ...,\n",
       "             7.7836e-02, -8.7652e-02,  4.1448e-02],\n",
       "           [-4.6903e-03,  1.7401e-03, -2.5247e-02,  ...,\n",
       "            -1.8898e-02,  1.1238e-02, -1.1413e-02]],\n",
       "\n",
       "          [[ 6.6121e-03, -9.4386e-03,  2.0548e-02,  ...,\n",
       "            -1.7568e-02,  3.2777e-03,  1.6559e-03],\n",
       "           [-1.5395e-02,  1.7907e-02, -8.8572e-03,  ...,\n",
       "             6.3842e-03, -7.3438e-03, -4.4029e-03],\n",
       "           [ 1.7646e-02, -1.4741e-02, -1.2486e-02,  ...,\n",
       "            -7.1227e-02, -7.2066e-04,  1.1478e-02],\n",
       "           ...,\n",
       "           [-1.1896e-02,  3.1222e-02,  3.9697e-02,  ...,\n",
       "             1.7477e-01, -1.5124e-02, -1.9732e-02],\n",
       "           [-3.8018e-03,  3.3597e-02, -6.6162e-02,  ...,\n",
       "             7.7836e-02, -8.7652e-02,  4.1448e-02],\n",
       "           [-4.6903e-03,  1.7401e-03, -2.5247e-02,  ...,\n",
       "            -1.8898e-02,  1.1238e-02, -1.1413e-02]],\n",
       "\n",
       "          [[ 6.6121e-03, -9.4386e-03,  2.0548e-02,  ...,\n",
       "            -1.7568e-02,  3.2777e-03,  1.6559e-03],\n",
       "           [-1.5395e-02,  1.7907e-02, -8.8572e-03,  ...,\n",
       "             6.3842e-03, -7.3438e-03, -4.4029e-03],\n",
       "           [ 1.7646e-02, -1.4741e-02, -1.2486e-02,  ...,\n",
       "            -7.1227e-02, -7.2066e-04,  1.1478e-02],\n",
       "           ...,\n",
       "           [-1.1896e-02,  3.1222e-02,  3.9697e-02,  ...,\n",
       "             1.7477e-01, -1.5124e-02, -1.9732e-02],\n",
       "           [-3.8018e-03,  3.3597e-02, -6.6162e-02,  ...,\n",
       "             7.7836e-02, -8.7652e-02,  4.1448e-02],\n",
       "           [-4.6903e-03,  1.7401e-03, -2.5247e-02,  ...,\n",
       "            -1.8898e-02,  1.1238e-02, -1.1413e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 6.2086e-03, -1.3027e-02,  1.3830e-02,  ...,\n",
       "            -1.4103e-02,  9.1179e-03, -1.7765e-03],\n",
       "           [-1.5104e-02,  2.0842e-02, -6.3129e-03,  ...,\n",
       "             9.7057e-03,  1.0110e-03, -6.0919e-04],\n",
       "           [ 1.2329e-02, -2.1976e-02, -7.2151e-03,  ...,\n",
       "            -8.6759e-02,  1.8678e-02,  1.2599e-02],\n",
       "           ...,\n",
       "           [-1.1555e-02,  4.3330e-02,  4.1157e-02,  ...,\n",
       "             2.1727e-01, -5.5576e-03, -4.1156e-02],\n",
       "           [-6.5322e-03,  4.0788e-02, -8.2948e-02,  ...,\n",
       "             1.1014e-01, -1.0677e-01,  3.1462e-02],\n",
       "           [ 6.9792e-04,  8.4058e-03, -2.7663e-02,  ...,\n",
       "            -2.3006e-02,  6.7931e-03, -5.1458e-03]],\n",
       "\n",
       "          [[ 6.2086e-03, -1.3027e-02,  1.3830e-02,  ...,\n",
       "            -1.4103e-02,  9.1179e-03, -1.7765e-03],\n",
       "           [-1.5104e-02,  2.0842e-02, -6.3129e-03,  ...,\n",
       "             9.7057e-03,  1.0110e-03, -6.0919e-04],\n",
       "           [ 1.2329e-02, -2.1976e-02, -7.2151e-03,  ...,\n",
       "            -8.6759e-02,  1.8678e-02,  1.2599e-02],\n",
       "           ...,\n",
       "           [-1.1555e-02,  4.3330e-02,  4.1157e-02,  ...,\n",
       "             2.1727e-01, -5.5576e-03, -4.1156e-02],\n",
       "           [-6.5322e-03,  4.0788e-02, -8.2948e-02,  ...,\n",
       "             1.1014e-01, -1.0677e-01,  3.1462e-02],\n",
       "           [ 6.9792e-04,  8.4058e-03, -2.7663e-02,  ...,\n",
       "            -2.3006e-02,  6.7931e-03, -5.1458e-03]],\n",
       "\n",
       "          [[ 6.2086e-03, -1.3027e-02,  1.3830e-02,  ...,\n",
       "            -1.4103e-02,  9.1179e-03, -1.7765e-03],\n",
       "           [-1.5104e-02,  2.0842e-02, -6.3129e-03,  ...,\n",
       "             9.7057e-03,  1.0110e-03, -6.0919e-04],\n",
       "           [ 1.2329e-02, -2.1976e-02, -7.2151e-03,  ...,\n",
       "            -8.6759e-02,  1.8678e-02,  1.2599e-02],\n",
       "           ...,\n",
       "           [-1.1555e-02,  4.3330e-02,  4.1157e-02,  ...,\n",
       "             2.1727e-01, -5.5576e-03, -4.1156e-02],\n",
       "           [-6.5322e-03,  4.0788e-02, -8.2948e-02,  ...,\n",
       "             1.1014e-01, -1.0677e-01,  3.1462e-02],\n",
       "           [ 6.9792e-04,  8.4058e-03, -2.7663e-02,  ...,\n",
       "            -2.3006e-02,  6.7931e-03, -5.1458e-03]]],\n",
       "\n",
       "\n",
       "         [[[ 4.3561e-03, -1.2361e-02,  6.6540e-03,  ...,\n",
       "            -1.5470e-02,  8.7138e-03,  8.6510e-04],\n",
       "           [-1.1101e-02,  2.5103e-02, -9.6109e-03,  ...,\n",
       "             1.5833e-02, -2.4118e-03, -5.3184e-03],\n",
       "           [ 2.0398e-02, -1.4972e-02, -4.5499e-02,  ...,\n",
       "            -4.3379e-02,  2.1268e-03,  4.5852e-03],\n",
       "           ...,\n",
       "           [-5.2307e-03,  2.7137e-03,  4.8581e-02,  ...,\n",
       "             1.5486e-01, -5.5875e-02, -9.4964e-03],\n",
       "           [-1.5109e-02,  1.2448e-02, -4.1784e-02,  ...,\n",
       "             3.5205e-02, -9.2394e-02,  5.5640e-02],\n",
       "           [ 3.4852e-03,  6.3400e-03, -5.1170e-03,  ...,\n",
       "            -3.7832e-02,  2.2538e-02, -2.2550e-03]],\n",
       "\n",
       "          [[ 4.3561e-03, -1.2361e-02,  6.6540e-03,  ...,\n",
       "            -1.5470e-02,  8.7138e-03,  8.6510e-04],\n",
       "           [-1.1101e-02,  2.5103e-02, -9.6109e-03,  ...,\n",
       "             1.5833e-02, -2.4118e-03, -5.3184e-03],\n",
       "           [ 2.0398e-02, -1.4972e-02, -4.5499e-02,  ...,\n",
       "            -4.3379e-02,  2.1268e-03,  4.5852e-03],\n",
       "           ...,\n",
       "           [-5.2307e-03,  2.7137e-03,  4.8581e-02,  ...,\n",
       "             1.5486e-01, -5.5875e-02, -9.4964e-03],\n",
       "           [-1.5109e-02,  1.2448e-02, -4.1784e-02,  ...,\n",
       "             3.5205e-02, -9.2394e-02,  5.5640e-02],\n",
       "           [ 3.4852e-03,  6.3400e-03, -5.1170e-03,  ...,\n",
       "            -3.7832e-02,  2.2538e-02, -2.2550e-03]],\n",
       "\n",
       "          [[ 4.3561e-03, -1.2361e-02,  6.6540e-03,  ...,\n",
       "            -1.5470e-02,  8.7138e-03,  8.6510e-04],\n",
       "           [-1.1101e-02,  2.5103e-02, -9.6109e-03,  ...,\n",
       "             1.5833e-02, -2.4118e-03, -5.3184e-03],\n",
       "           [ 2.0398e-02, -1.4972e-02, -4.5499e-02,  ...,\n",
       "            -4.3379e-02,  2.1268e-03,  4.5852e-03],\n",
       "           ...,\n",
       "           [-5.2307e-03,  2.7137e-03,  4.8581e-02,  ...,\n",
       "             1.5486e-01, -5.5875e-02, -9.4964e-03],\n",
       "           [-1.5109e-02,  1.2448e-02, -4.1784e-02,  ...,\n",
       "             3.5205e-02, -9.2394e-02,  5.5640e-02],\n",
       "           [ 3.4852e-03,  6.3400e-03, -5.1170e-03,  ...,\n",
       "            -3.7832e-02,  2.2538e-02, -2.2550e-03]]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Parameter(torch.Tensor):\n",
    "    r\"\"\"A kind of Tensor that is to be considered a module parameter.\n",
    "\n",
    "    Parameters are :class:`~torch.Tensor` subclasses, that have a\n",
    "    very special property when used with :class:`Module` s - when they're\n",
    "    assigned as Module attributes they are automatically added to the list of\n",
    "    its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n",
    "    Assigning a Tensor doesn't have such effect. This is because one might\n",
    "    want to cache some temporary state, like last hidden state of the RNN, in\n",
    "    the model. If there was no such class as :class:`Parameter`, these\n",
    "    temporaries would get registered too.\n",
    "\n",
    "    Arguments:\n",
    "        data (Tensor): parameter tensor.\n",
    "        requires_grad (bool, optional): if the parameter requires gradient. See\n",
    "            :ref:`excluding-subgraphs` for more details. Default: `True`\n",
    "    \"\"\"\n",
    "    def __new__(cls, data=None, requires_grad=True):\n",
    "        if data is None:\n",
    "            data = torch.Tensor()\n",
    "        return torch.Tensor._make_subclass(cls, data, requires_grad)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Parameter containing:\\n' + super(Parameter, self).__repr__()\n",
    "\n",
    "    def __reduce_ex__(self, proto):\n",
    "        return Parameter, (super(Parameter, self), self.requires_grad)\n",
    "Parameter(weight_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3d.weight = torch.nn.Parameter(weight_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.nn.Parameter(weight_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (video)",
   "language": "python",
   "name": "video"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
